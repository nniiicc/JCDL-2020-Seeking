
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

@article{merton1942science,
  title={Science and technology in a democratic order},
  author={Merton, Robert K},
  journal={Journal of legal and political sociology},
  volume={1},
  number={1},
  pages={115--126},
  year={1942},
  publisher={New York}
}


@report{hengel_publishing_2017,
	title = {Publishing while Female. Are women held to higher standards? Evidence from peer review.},
	url = {https://www.repository.cam.ac.uk/handle/1810/270621},
	shorttitle = {Publishing while Female. Are women held to higher standards?},
	abstract = {I use readability scores to test if referees and/or editors apply higher standards to women's writing in academic peer review. I find: (i) female-authored papers are 1-6 percent better written than equivalent papers by men; (ii) the gap is two times higher in published articles than in earlier, draft versions of the same papers; (iii) women's writing gradually improves but men's does not-meaning the readability gap grows over authors' careers. In a dynamic model of an author's decision-making process, I show that tougher editorial standards and/or biased referee assignment are uniquely consistent with this pattern of choices. A conservative causal estimate derived from the model suggests senior female economists write at least 9 percent more clearly than they otherwise would. These findings indicate that higher standards burden women with an added time tax and probably contribute to academia's "Publishing Paradox" Consistent with this hypothesis, I find female-authored papers spend six months longer in peer review. More generally, tougher standards impose a quantity/quality tradeoff that characterises many instances of female output. They could resolve persistently lower-otherwise unexplained-female productivity in many high-skill occupations.},
	institution = {University of Cambridge},
	type = {Working Paper},
	author = {Hengel, E.},
	urldate = {2019-10-22},
	date = {2017-12-04},
	langid = {english},
	doi = {10.17863/CAM.17548},
	file = {Full Text PDF:/Users/nmweber/Zotero/storage/LPNRZACX/Hengel - 2017 - Publishing while Female. Are women held to higher .pdf:application/pdf;Snapshot:/Users/nmweber/Zotero/storage/3XZDH4EC/270621.html:text/html}
}

@online{noauthor_strict_2018,
	title = {Do strict data sharing policies affect submissions?},
	url = {https://scholarlykitchen.sspnet.org/2018/09/25/does-adopting-a-strict-data-sharing-policy-affect-submissions/},
	abstract = {Journal Editors commonly fear that data policies will hurt submissions, but data from 12 evolution and ecology journals say otherwise.},
	titleaddon = {The Scholarly Kitchen},
	urldate = {2019-10-21},
	date = {2018-09-25},
	langid = {american},
	file = {Snapshot:/Users/nmweber/Zotero/storage/IQTU6PTF/does-adopting-a-strict-data-sharing-policy-affect-submissions.html:text/html}
}

@article{couture_funder-imposed_2018,
	title = {A funder-imposed data publication requirement seldom inspired data sharing},
	volume = {13},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0199789},
	doi = {10.1371/journal.pone.0199789},
	abstract = {Growth of the open science movement has drawn significant attention to data sharing and availability across the scientific community. In this study, we tested the ability to recover data collected under a particular funder-imposed requirement of public availability. We assessed overall data recovery success, tested whether characteristics of the data or data creator were indicators of recovery success, and identified hurdles to data recovery. Overall the majority of data were not recovered (26\% recovery of 315 data projects), a similar result to journal-driven efforts to recover data. Field of research was the most important indicator of recovery success, but neither home agency sector nor age of data were determinants of recovery. While we did not find a relationship between recovery of data and age of data, age did predict whether we could find contact information for the grantee. The main hurdles to data recovery included those associated with communication with the researcher; loss of contact with the data creator accounted for half (50\%) of unrecoverable datasets, and unavailability of contact information accounted for 35\% of unrecoverable datasets. Overall, our results suggest that funding agencies and journals face similar challenges to enforcement of data requirements. We advocate that funding agencies could improve the availability of the data they fund by dedicating more resources to enforcing compliance with data requirements, providing data-sharing tools and technical support to awardees, and administering stricter consequences for those who ignore data sharing preconditions.},
	pages = {e0199789},
	number = {7},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Couture, Jessica L. and Blake, Rachael E. and {McDonald}, Gavin and Ward, Colette L.},
	urldate = {2019-10-21},
	date = {2018-07-06},
	langid = {english},
	keywords = {Data management, Communications, Data acquisition, Language, Open science, Public policy, Research grants, Science policy},
	file = {Full Text PDF:/Users/nmweber/Zotero/storage/YWUB8UA9/Couture et al. - 2018 - A funder-imposed data publication requirement seld.pdf:application/pdf;Snapshot:/Users/nmweber/Zotero/storage/QUWFENB2/article.html:text/html}
}

@incollection{gergle_experimental_2014,
	location = {New York, {NY}},
	title = {Experimental Research in {HCI}},
	isbn = {978-1-4939-0378-8},
	url = {https://doi.org/10.1007/978-1-4939-0378-8_9},
	abstract = {In Experiments, researchers set up comparable situations in which they carefully manipulate variables and collect people’s behavior in each condition. Experiments are very effective in determining causation in controlled situations and complement techniques that investigate ongoing behavior in more natural settings. For example, experiments are excellent for determining whether increased audio quality reduces blood pressure of participants in a video conference, and can add important insights to the larger question of when people choose video conferences over audio-only ones.},
	pages = {191--227},
	booktitle = {Ways of Knowing in {HCI}},
	publisher = {Springer New York},
	author = {Gergle, Darren and Tan, Desney S.},
	editor = {Olson, Judith S. and Kellogg, Wendy A.},
	urldate = {2019-10-21},
	date = {2014},
	langid = {english},
	doi = {10.1007/978-1-4939-0378-8_9},
	keywords = {Display Size, Experimental Research, Frame Rate, Large Display, Random Assignment}
}


@article{omahoney_data_2019,
	title = {Data for: Making the real: Rhetorical adduction and the Bangladesh Liberation War},
	url = {https://data.qdr.syr.edu/dataset.xhtml?persistentId=doi:10.5064/F6M2H9VQ},
	doi = {10.5064/F6M2H9VQ},
	abstract = {This is an Annotation for Transparent Inquiry (ATI) data project.  The annotated article can be viewed on the publisher's website.    The overarchi...},
	language = {en},
	publisher = {Qualitative Data Repository},
	urldate = {2019-07-22},
	author = {O'Mahoney, Joseph},
	month = feb,
	year = {2019}
}

@incollection{oulasvirta_field_2009,
	location = {London},
	title = {Field Experiments in {HCI}: Promises and Challenges},
	isbn = {978-1-84800-385-9},
	url = {https://doi.org/10.1007/978-1-84800-385-9_5},
	shorttitle = {Field Experiments in {HCI}},
	abstract = {Experimental methods have been under criticism since the advent of mobile and ubiquitous technologies, due to clear limitations in their suitability for studies in the field. However, the laboratory paradigm cannot be directly transferred to field conditions because of its strict notions of experimentation. This chapter examines the theory of quasi-experimentation as an alternative conceptualization of causality, control, and validity. Several threats to experimental validity in field experiments in {HCI} are discussed. These concerns must be addressed at all levels of experimentation, from the design and execution of a field experiment to analysis of data. Noteworthy also are new technical solutions that have enabled high-fidelity data collection and that generally support endeavors in ensuring validity. If field experimentation is to become the de facto standard of research in human–computer interaction, the methodological core and technical tools must be developed in concert.},
	pages = {87--116},
	booktitle = {Future Interaction Design {II}},
	publisher = {Springer London},
	author = {Oulasvirta, Antti},
	editor = {Isomäki, Hannakaisa and Saariluoma, Pertti},
	urldate = {2019-10-21},
	date = {2009},
	langid = {english},
	doi = {10.1007/978-1-84800-385-9_5},
	keywords = {Mobile Device, Mobile Phone, Navigation Task, Task Completion Time, Ubiquitous Technology}
}

@article{pedersen_empiricism_2008,
	title = {Empiricism Is Not a Matter of Faith},
	volume = {34},
	issn = {0891-2017, 1530-9312},
	url = {http://www.mitpressjournals.org/doi/10.1162/coli.2008.34.3.465},
	doi = {10.1162/coli.2008.34.3.465},
	pages = {465--470},
	number = {3},
	journaltitle = {Computational Linguistics},
	author = {Pedersen, Ted},
	urldate = {2019-10-20},
	date = {2008-09},
	langid = {english},
	file = {Pedersen - 2008 - Empiricism Is Not a Matter of Faith.pdf:/Users/nmweber/Zotero/storage/NWUN56AI/Pedersen - 2008 - Empiricism Is Not a Matter of Faith.pdf:application/pdf}
}

@article{mutlu_human-computer_nodate,
	title = {{HUMAN}-{COMPUTER} {INTERACTION} {EXPERIMENTAL} {DESIGN}},
	pages = {41},
	author = {Mutlu, Bilge},
	langid = {english},
	file = {Mutlu - HUMAN-COMPUTER INTERACTION EXPERIMENTAL DESIGN.pdf:/Users/nmweber/Zotero/storage/DHHZKGE5/Mutlu - HUMAN-COMPUTER INTERACTION EXPERIMENTAL DESIGN.pdf:application/pdf}
}

@online{noauthor_robert_nodate,
	title = {Robert K. Merton, The Normative Structure of Science (1942)},
	url = {https://www.panarchy.org/merton/science.html},
	urldate = {2019-10-15}
}

@article{morey_peer_2015,
	title = {The Peer Reviewers' Openness Initiative: incentivizing open research practices through peer review},
	url = {https://royalsocietypublishing.org/doi/abs/10.1098/rsos.150547},
	shorttitle = {The Peer Reviewers' Openness Initiative},
	abstract = {Openness is one of the central values of science. Open scientific practices such as sharing data, materials and analysis scripts alongside published articles have many benefits, including easier re...},
	journaltitle = {Royal Society Open Science},
	author = {Morey, Richard D. and Chambers, Christopher D. and Etchells, Peter J. and Harris, Christine R. and Hoekstra, Rink and Lakens, Daniël and Lewandowsky, Stephan and Morey, Candice Coker and Newman, Daniel P. and Schönbrodt, Felix D. and Vanpaemel, Wolf and Wagenmakers, Eric-Jan and Zwaan, Rolf A.},
	urldate = {2019-10-15},
	date = {2015-10-10},
	langid = {english}
}


@article{crosas_data_2018,
	title = {Data policies of highly-ranked social science journals},
	url = {https://osf.io/preprints/socarxiv/9h7ay/},
	doi = {10.17605/OSF.IO/9H7AY},
	abstract = {By encouraging and requiring that authors share their data in order to publish articles, scholarly journals have become an important actor in the movement to improve the openness of data and the reproducibility of research. But how many social science journals encourage or mandate that authors share the data supporting their research findings? How does the share of journal data policies vary by discipline? What influences these journals’ decisions to adopt such policies and instructions? And what do those policies and instructions look like?
We discuss the results of our analysis of the instructions and policies of 291 highly-ranked journals publishing social science research, where we studied the contents of journal data policies and instructions across 14 variables, such as when and how authors are asked to share their data, and what role journal ranking and age play in the existence and quality of data policies and instructions. We also compare our results to the results of other studies that have analyzed the policies of social science journals, although differences in the journals chosen and how each study defines what constitutes a data policy limit this comparison.
We conclude that a little more than half of the journals in our study have data policies. A greater share of the economics journals have data policies and mandate sharing, followed by political science/international relations and psychology journals.
Finally, we use our findings to make several recommendations: Policies should include the terms “data,” “dataset” or more specific terms that make it clear what to make available; policies should include the benefits of data sharing; journals, publishers, and associations need to collaborate more to clarify data policies; and policies should explicitly ask for qualitative data.},
	urldate = {2018-04-03},
	journal = {SocArXiv},
	author = {Crosas, Mercè and Gautier, Julian and Karcher, Sebastian and Kirilova, Dessi and Otalora, Gerard and Schwartz, Abigail},
	month = mar,
	year = {2018},
	file = {Crosas et al_2018_Data policies of highly-ranked social science journals.pdf:C\:\\Users\\skarcher\\Zotero\\storage\\7R986HS6\\Crosas et al_2018_Data policies of highly-ranked social science journals.pdf:application/pdf}
}

@article{kratz_researcher_2015,
	title = {Researcher Perspectives on Publication and Peer Review of Data},
	volume = {10},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0117619},
	doi = {10.1371/journal.pone.0117619},
	abstract = {Data “publication” seeks to appropriate the prestige of authorship in the peer-reviewed literature to reward researchers who create useful and well-documented datasets. The scholarly communication community has embraced data publication as an incentive to document and share data. But, numerous new and ongoing experiments in implementation have not yet resolved what a data publication should be, when data should be peer-reviewed, or how data peer review should work. While researchers have been surveyed extensively regarding data management and sharing, their perceptions and expectations of data publication are largely unknown. To bring this important yet neglected perspective into the conversation, we surveyed ∼ 250 researchers across the sciences and social sciences– asking what expectations“data publication” raises and what features would be useful to evaluate the trustworthiness, evaluate the impact, and enhance the prestige of a data publication. We found that researcher expectations of data publication center on availability, generally through an open database or repository. Few respondents expected published data to be peer-reviewed, but peer-reviewed data enjoyed much greater trust and prestige. The importance of adequate metadata was acknowledged, in that almost all respondents expected data peer review to include evaluation of the data’s documentation. Formal citation in the reference list was affirmed by most respondents as the proper way to credit dataset creators. Citation count was viewed as the most useful measure of impact, but download count was seen as nearly as valuable. These results offer practical guidance for data publishers seeking to meet researcher expectations and enhance the value of published data.},
	pages = {e0117619},
	number = {2},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Kratz, John Ernest and Strasser, Carly},
	urldate = {2019-10-11},
	date = {2015-02-23},
	langid = {english},
	keywords = {Data management, Peer review, Scientists, Biologists, Citation analysis, Social sciences, Surveys, United States},
}


@techreport{hardwicke_data_2018,
	type = {preprint},
	title = {Data availability, reusability, and analytic reproducibility: {Evaluating} the impact of a mandatory open data policy at the journal {Cognition}},
	shorttitle = {Data availability, reusability, and analytic reproducibility},
	url = {https://osf.io/39cfb},
	abstract = {Access to data is a critical feature of an efficient, progressive, and ultimately self-correcting scientific ecosystem. But the extent to which in-principle benefits of data sharing are realized in practice is unclear. Crucially, it is largely unknown whether published findings can be reproduced by repeating reported analyses upon shared data (“analytic reproducibility”). To investigate, we conducted an observational evaluation of a mandatory open data policy introduced at the journal Cognition. Interrupted time-series analyses indicated a substantial post-policy increase in data available statements (104/417, 25\% pre-policy to 136/174, 78\% post-policy), although not all data appeared reusable (23/104, 22\% pre-policy to 85/136, 62\%, post-policy). For 35 of the articles determined to have reusable data, we attempted to reproduce 1324 target values. Ultimately, 64 values could not be reproduced within a 10\% margin of error. For 22 articles all target values were reproduced, but 11 of these required author assistance. For 13 articles at least one value could not be reproduced despite author assistance. Importantly there were no clear indications that original conclusions were seriously impacted. Mandatory open data policies can increase the frequency and quality of data sharing. However, suboptimal data curation, unclear analysis specification, and reporting errors can impede analytic reproducibility, undermining the utility of data sharing and the credibility of scientific findings.},
	urldate = {2020-01-24},
	institution = {BITSS},
	author = {Hardwicke, Tom Elis and Mathur, Maya B and MacDonald, Kyle Earl and Nilsonne, Gustav and Banks, George Christopher and Kidwell, Mallory and Hofelich Mohr, Alicia and Clayton, Elizabeth and Yoon, Erica J. and Tessler, Michael Henry and Lenne, Richie L and Altman, Sara Kai and Long, Bria and Frank, Michael C.},
	month = mar,
	year = {2018},
	doi = {10.31222/osf.io/39cfb},
}


@article{vanpaemel_are_2015,
	title = {Are we wasting a good crisis? {The} availability of psychological research data after the storm},
	volume = {1},
	copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are ©, ® or ™ of their respective owners. No challenge to any owner’s rights is intended or should be inferred.},
	issn = {2474-7394},
	shorttitle = {Are we wasting a good crisis?},
	url = {http://www.collabra.org/articles/10.1525/collabra.13/},
	doi = {10.1525/collabra.13},
	abstract = {Article: Are We Wasting a Good Crisis? The Availability of Psychological Research Data after the Storm},
	language = {eng},
	number = {1},
	urldate = {2020-01-24},
	journal = {Collabra: Psychology},
	author = {Vanpaemel, Wolf and Vermorgen, Maarten and Deriemaecker, Leen and Storms, Gert},
	month = oct,
	year = {2015},
	pages = {Art. 3},
}

@article{david_introduction_2017,
	title = {An introduction to the special issue on Geoscience Papers of the Future},
	rights = {©2016. The Authors.},
	issn = {2333-5084},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1002/2016EA000201%4010.1002/%28ISSN%292333-5084.GPF1},
	doi = {10.1002/2016EA000201@10.1002/(ISSN)2333-5084.GPF1},
	abstract = {Advocates of enhanced quality for published scientific results are increasingly voicing the need for further transparency of data and software for scientific reproducibility. However, such advanced digital scholarship can appear perplexing to geoscientists that are seduced by the concept of open science yet wonder about the exact mechanics and implications of the associated efforts. This special issue of Earth and Space Science entitled “Geoscience Papers of the Future” includes a review of existing best practices for digital scholarship and bundles a set of example articles that share their digital research products and reflect on the process of opening their scientific approach in a common quest for reproducible science.},
	pages = {441--444},
	journaltitle = {Earth and Space Science},
	author = {David, Cédric H. and Gil, Yolanda and Duffy, Christopher J. and Peckham, Scott D. and Venayagamoorthy, S. Karan},
	urldate = {2019-10-11},
	date = {2017},
	langid = {english},
	keywords = {data, {GPF}, open, provenance, reproducibility, software},
	file = {Full Text PDF:/Users/nmweber/Zotero/storage/NP2D5HJV/David et al. - 2017 - An introduction to the special issue on Geoscience.pdf:application/pdf;Snapshot:/Users/nmweber/Zotero/storage/DEQCIIW9/(ISSN)2333-5084.html:text/html}
}

@article{li_data_nodate,
	title = {Data objects and documenting scientific processes: An analysis of data events in biodiversity data papers},
	volume = {0},
	rights = {© 2019 {ASIS}\&T},
	issn = {2330-1643},
	url = {https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.24226},
	doi = {10.1002/asi.24226},
	shorttitle = {Data objects and documenting scientific processes},
	abstract = {The data paper, an emerging scholarly genre, describes research data sets and is intended to bridge the gap between the publication of research data and scientific articles. Research examining how data papers report data events, such as data transactions and manipulations, is limited. The research reported on in this article addresses this limitation and investigated how data events are inscribed in data papers. A content analysis was conducted examining the full texts of 82 data papers, drawn from the curated list of data papers connected to the Global Biodiversity Information Facility. Data events recorded for each paper were organized into a set of 17 categories. Many of these categories are described together in the same sentence, which indicates the messiness of data events in the laboratory space. The findings challenge the degrees to which data papers are a distinct genre compared to research articles and they describe data-centric research processes in a through way. This article also discusses how our results could inform a better data publication ecosystem in the future.},
	number = {0},
	journaltitle = {Journal of the Association for Information Science and Technology},
	author = {Li, Kai and Greenberg, Jane and Dunic, Jillian},
	urldate = {2019-10-11},
	langid = {english},
	file = {Snapshot:/Users/nmweber/Zotero/storage/8U9VHN7B/asi.html:text/html}
}

@article{christensen_study_2019,
	title = {A study of the impact of data sharing on article citations using journal policies as a natural experiment},
	volume = {14},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0225883},
	doi = {10.1371/journal.pone.0225883},
	abstract = {This study estimates the effect of data sharing on the citations of academic articles, using journal policies as a natural experiment. We begin by examining 17 high-impact journals that have adopted the requirement that data from published articles be publicly posted. We match these 17 journals to 13 journals without policy changes and find that empirical articles published just before their change in editorial policy have citation rates with no statistically significant difference from those published shortly after the shift. We then ask whether this null result stems from poor compliance with data sharing policies, and use the data sharing policy changes as instrumental variables to examine more closely two leading journals in economics and political science with relatively strong enforcement of new data policies. We find that articles that make their data available receive 97 additional citations (estimate standard error of 34). We conclude that: a) authors who share data may be rewarded eventually with additional scholarly citations, and b) data-posting policies alone do not increase the impact of articles published in a journal unless those policies are enforced.},
	language = {en},
	number = {12},
	urldate = {2020-01-24},
	journal = {PLOS ONE},
	author = {Christensen, Garret and Dafoe, Allan and Miguel, Edward and Moore, Don A. and Rose, Andrew K.},
	month = dec,
	year = {2019},
	pages = {e0225883},
}


@article{piwowar_sharing_2007,
	title = {Sharing detailed research data is associated with increased citation rate},
	volume = {2},
	issn = {1932-6203},
	url = {http://dx.plos.org/10.1371/journal.pone.0000308},
	doi = {10.1371/journal.pone.0000308},
	language = {en},
	number = {3},
	urldate = {2016-02-26},
	journal = {PLoS ONE},
	author = {Piwowar, Heather A. and Day, Roger S. and Fridsma, Douglas B.},
	editor = {Ioannidis, John},
	month = mar,
	year = {2007},
	keywords = {citation},
	pages = {e308},
	file = {Piwowar, Day, & Fridsma (2007) Sharing Detailed Research Data Is Associated with Increased Citation Rate.pdf:C\:\\Users\\skarcher\\Zotero\\storage\\2CBKM73B\\Piwowar, Day, & Fridsma (2007) Sharing Detailed Research Data Is Associated with Increased Citation Rate.pdf:application/pdf}
}


@article{bailar_journal_1985,
	title = {Journal peer review: the need for a research agenda},
	volume = {312},
	copyright = {Copyright Massachusetts Medical Society Mar 7, 1985},
	issn = {00284793},
	shorttitle = {Journal peer review},
	url = {https://search.proquest.com/docview/1877903706/citation/2BBA5D8E6C0C4BFFPQ/1},
	doi = {10.1056/nejm198503073121023},
	language = {English},
	number = {10},
	urldate = {2020-01-24},
	journal = {The New England Journal of Medicine; Boston},
	author = {Bailar, John C. and Patterson, Kay},
	month = mar,
	year = {1985},
	pages = {654--657},
	file = {Bailar_Patterson_1985_Journal Peer Review.pdf:C\:\\Users\\skarcher\\Zotero\\storage\\243M8NQ8\\Bailar_Patterson_1985_Journal Peer Review.pdf:application/pdf}
}
@article{lee_promote_2017,
	title = {Promote scientific integrity via journal peer review data},
	volume = {357},
	rights = {Copyright © 2017 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. http://www.sciencemag.org/about/science-licenses-journal-article-{reuseThis} is an article distributed under the terms of the Science Journals Default License.},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/357/6348/256},
	doi = {10.1126/science.aan4141},
	abstract = {Publishers must invest, and manage risk
Publishers must invest, and manage risk},
	pages = {256--257},
	number = {6348},
	journaltitle = {Science},
	author = {Lee, Carole J. and Moher, David},
	urldate = {2019-10-08},
	date = {2017-07-21},
	langid = {english},
	pmid = {28729501},
	file = {Full Text PDF:/Users/nmweber/Zotero/storage/4MJTDAAU/Lee and Moher - 2017 - Promote scientific integrity via journal peer revi.pdf:application/pdf;Snapshot:/Users/nmweber/Zotero/storage/VLD4UX8N/256.html:text/html}
}

@article{parsons_data_2010,
	title = {Data Citation and Peer Review},
	volume = {91},
	issn = {2324-9250},
	url = {https://agupubs.pericles-prod.literatumonline.com/doi/abs/10.1029/2010EO340001},
	doi = {10.1029/2010EO340001},
	abstract = {A scientific publication is fundamentally an argument consisting of a set of ideas and expectations supported by observations and calculations that serve as evidence of its veracity. An argument without evidence is only a set of assertions. Consider the difference between the statement “The hairy woodpecker population is declining in the northwest region of the United States” and the statement “Hairy woodpecker populations in the northwest region of the United States have declined by 11\% between 1992 and 2003, according to data from the Institute for Bird Populations (http://www.birdpop.org/).” Both or neither of these statements could be true, but only the second one can be verified. Scientific papers do, of course, present specific data points as evidence for their arguments, but how well do papers guide readers to the body of those data, where the the data's integrity can be further examined? In practice, a chasm may lie across the path of a reviewer seeking the source data of a scientific argument.},
	pages = {297--298},
	number = {34},
	journaltitle = {Eos, Transactions American Geophysical Union},
	author = {Parsons, Mark A. and Duerr, Ruth and Minster, Jean-Bernard},
	urldate = {2019-10-08},
	date = {2010},
	langid = {english},
	keywords = {informatics, citation},
}


@book{royal_society_great_britain_science_2012,
	title = {Science as an open enterprise},
	isbn = {978-0-85403-962-3},
	author = {{Royal Society (Great Britain)} and {Science Policy Centre} and {Royal Society (Great Britain)}},
	date = {2012},
	langid = {english},
	note = {{OCLC}: 840187578},
	file = {Royal Society (Great Britain) et al. - 2012 - Science as an open enterprise.pdf:/Users/nmweber/Zotero/storage/6V8V9K7I/Royal Society (Great Britain) et al. - 2012 - Science as an open enterprise.pdf:application/pdf}
}

@article{open2012open,
  title={An open, large-scale, collaborative effort to estimate the reproducibility of psychological science},
  author={Open Science Collaboration},
  journal={Perspectives on Psychological Science},
  volume={7},
  number={6},
  pages={657--660},
  year={2012},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@book{fischer2019politics,
  title={Politics, values, and public policy: The problem of methodology},
  author={Fischer, Frank},
  year={2019},
  publisher={Routledge}
}

@article{nicholls2016reporting,
  title={Reporting transparency: making the ethical mandate explicit},
  author={Nicholls, Stuart G and Langan, Sin{\'e}ad M and Benchimol, Eric I and Moher, David},
  journal={BMC medicine},
  volume={14},
  number={1},
  pages={44},
  year={2016},
  publisher={BioMed Central}
}

@article{wilkinson2016fair,
  title={The FAIR Guiding Principles for scientific data management and stewardship},
  author={Wilkinson, Mark D and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E and others},
  journal={Scientific data},
  volume={3},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{elman2014data,
  title={Data access and research transparency in the qualitative tradition},
  author={Elman, Colin and Kapiszewski, Diana},
  journal={PS: Political Science \& Politics},
  volume={47},
  number={1},
  pages={43--47},
  year={2014},
  publisher={Cambridge University Press}
}
@article{jasanoff2006transparency,
  title={Transparency in Public Science Purposes, Reasons, Limits},
  author={Jasanoff, Shiela},
  journal={Law \& contemp. probs.},
  volume={69},
  pages={21},
  year={2006},
  publisher={HeinOnline}
}

@article{spier2002history,
  title={The history of the peer-review process},
  author={Spier, Ray},
  journal={TRENDS in Biotechnology},
  volume={20},
  number={8},
  pages={357--358},
  year={2002},
  publisher={Elsevier}
}

@article{parsons2010data,
  title={Data citation and peer review},
  author={Parsons, Mark A and Duerr, Ruth and Minster, Jean-Bernard},
  journal={Eos, Transactions American Geophysical Union},
  volume={91},
  number={34},
  pages={297--298},
  year={2010},
  publisher={Wiley Online Library}
}
@article{anderson2008corpus,
  title={Corpus linguistics in the UK: Resources for sociolinguistic research},
  author={Anderson, Wendy},
  journal={Language and Linguistics Compass},
  volume={2},
  number={2},
  pages={352--371},
  year={2008},
  publisher={Wiley Online Library}
}

@article{tong2012enhancing,
  title={Enhancing transparency in reporting the synthesis of qualitative research: ENTREQ},
  author={Tong, Allison and Flemming, Kate and McInnes, Elizabeth and Oliver, Sandy and Craig, Jonathan},
  journal={BMC medical research methodology},
  volume={12},
  number={1},
  pages={181},
  year={2012},
  publisher={BioMed Central}
}

@article{peat2014improving,
  title={Improving the transparency of prognosis research: the role of reporting, data sharing, registration, and protocols},
  author={Peat, George and Riley, Richard D and Croft, Peter and Morley, Katherine I and Kyzas, Panayiotis A and Moons, Karel GM and Perel, Pablo and Steyerberg, Ewout W and Schroter, Sara and Altman, Douglas G and others},
  journal={PLoS medicine},
  volume={11},
  number={7},
  year={2014},
  publisher={Public Library of Science}
}

@article{anderson2013ethical,
  title={Ethical reproducibility: towards transparent reporting in biomedical research},
  author={Anderson, James A and Eijkholt, Marleen and Illes, Judy},
  journal={nature methods},
  volume={10},
  number={9},
  pages={843--845},
  year={2013},
  publisher={Nature Publishing Group}
}

@article{vasilevsky2017reproducible,
  title={Reproducible and reusable research: are journal data sharing policies meeting the mark?},
  author={Vasilevsky, Nicole A and Minnier, Jessica and Haendel, Melissa A and Champieux, Robin E},
  journal={PeerJ},
  volume={5},
  pages={e3208},
  year={2017},
  publisher={PeerJ Inc.}
}

@article{thelwall2017journal,
  title={Do journal data sharing mandates work? Life sciences evidence from Dryad},
  author={Thelwall, Mike and Kousha, Kayvan},
  journal={Aslib Journal of Information Management},
  year={2017},
  publisher={Emerald Publishing Limited}
}

@article{sturges2015research,
  title={Research data sharing: Developing a stakeholder-driven model for journal policies},
  author={Sturges, Paul and Bamkin, Marianne and Anders, Jane HS and Hubbard, Bill and Hussain, Azhar and Heeley, Melanie},
  journal={Journal of the Association for Information Science and Technology},
  volume={66},
  number={12},
  pages={2445--2455},
  year={2015},
  publisher={Wiley Online Library}
}

@article{schofield2009post,
  title={Post-publication sharing of data and tools},
  author={Schofield, Paul N and Bubela, Tania and Weaver, Thomas and Portilla, Lili and Brown, Stephen D and Hancock, John M and Einhorn, David and Tocchini-Valentini, Glauco and de Angelis, Martin Hrabe and Rosenthal, Nadia},
  journal={Nature},
  volume={461},
  number={7261},
  pages={171--173},
  year={2009},
  publisher={Nature Publishing Group}
}

@article{moravcsik2014transparency,
  title={Transparency: The revolution in qualitative research},
  author={Moravcsik, Andrew},
  journal={PS: Political Science \& Politics},
  volume={47},
  number={1},
  pages={48--53},
  year={2014},
  publisher={Cambridge University Press}
}

@article{elman2018qualitative,
  title={The Qualitative Data Repository’s Annotation for Transparent Inquiry (ATI) Initiative},
  author={Elman, Colin and Kapiszewski, Diana},
  journal={PS: Political Science \& Politics},
  volume={51},
  number={1},
  pages={3--6},
  year={2018},
  publisher={Cambridge University Press}
}

@article{karcher2019annotation,
  title={Annotation for transparent inquiry: Transparent data and analysis for qualitative research},
  author={Karcher, Sebastian and Weber, Nicholas},
  journal={IASSIST Quarterly},
  volume={43},
  number={2},
  pages={1--9},
  year={2019}
}

@article{braun2006using,
  title={Using thematic analysis in psychology},
  author={Braun, Virginia and Clarke, Victoria},
  journal={Qualitative research in psychology},
  volume={3},
  number={2},
  pages={77--101},
  year={2006},
  publisher={Taylor \& Francis}
}

